% Временные ряды. Динамические модели. Единичные корни и коинтеграция. Автокорреляционная и частичная автокорреляционная функции.

При рассмотрении регулярных временных рядов независимые переменные ($x_t$) называются \textbf{экзогенными}, зависимые ($y_t$) -- \textbf{эндогенными}.

Стандартной моделью является модель, в которой $y_t$ линейным образом зависит от лагированных экзогенных и эндогенных переменных:
\begin{equation}
\label{12_1}
    y_t =
    \delta + \sum_{i=1}^{q} \beta_i x_{t-i} + \sum_{j=1}^{p} \alpha_j y_{y-j} + \eps_t =
    \delta + A\left( L \right) \left[ y_t \right] + B\left( L \right) \left[ x_t \right] + \eps_t,
\end{equation}
где $L$ -- оператор лага, $A, B$ -- некоторые многочлены от одной переменной, $\eps_t$ -- случайные ошибки, удовлетворяющие условиям Гаусса-Маркова (то есть они независимы, обладают нулевым матожиданием и постоянной конечной дисперсией и некоррелированы с $x_t$). В случае, когда $p > 0$, то есть присутствует зависимость от лагированных эндогенных переменных, модель \eqref{12_1} называется \textbf{динамической}.


\begin{definition}[Стационарность]
    Ряд $y_t$ называется \textbf{стационарным в узком смысле}, если для любых $m, t$ для любого набора чисел $t_1, t_2, \dots, t_m$ следующие распределения совпадают:
    \begin{equation*}
        P\left( y_{t_1}, y_{t_2}, \dots, y_{t_m} \right) =
        P\left( y_{t_1+t}, y_{t_2+t}, \dots, y_{t_m+t} \right).
    \end{equation*}
    и \textbf{стационарным в широком смысле}, если его матожидание, дисперсия и ковариационная функция не завият от времени:
    \begin{equation*}
        \mean y_{t} = \mu < \infty,\;
        \var y_t = \gamma = \const,\;
        \cov\left( y_{t_1}, y_{t_2} \right) = K\left( t_1 - t_2 \right).
    \end{equation*}
\end{definition}

Рассмотрим авторегрессионный процесс 1 порядка (AR(1)):
\begin{equation}
\label{12_2}
    y_{t} = m + \phi y_{t-1} + \eps_t
    \iff
    y_t = \left( 1 - \phi L \right)^{-1} \left( m + \eps_t \right)
\end{equation}

Если $|\phi| < 1$, то последнее равенство также можно переписать в следующем виде:
\begin{gather*}
    y_t = \dots =
    \left( 1 + \phi L + \phi^2 L^2 + \dots \right) \left( m + \eps_t \right) =\\=
    \left( 1 + \phi + \phi^2 + \dots \right) m + \eps_t + \phi \eps_{t-1} + \phi^2 \eps_{t-2} + \dots.
\end{gather*}

Можно показать, что в таком случае $\mean y_t = \frac{m}{1-\phi}, \var y_t = \frac{\sigma^2}{1-\phi^2}, \cov\left( y_t, y_{t-k} \right) = \frac{\phi^k \sigma^2}{1 - \phi^2}$, следовательно, ряд стационарен в широком смысле.

Оценку $\hat\phi$ можно получить при помощи метода наименьших квадратов:
\begin{equation*}
    \hat\phi = \frac{\sum_{t} y_{t}y_{t-1}}{\sum_s y_s^2} = \phi + \left( \sum_t \frac{y_{t-1} \eps_t}{\sum_s y_{s-1}^2} \right),
\end{equation*}
причем в рассматриваемых предположениях эта оценка является состоятельной и асимптотически нормальной: $\sqrt{n}\left( \hat\phi - \phi \right) \to \mathcal{N}\left( 0, 1-\beta^2 \right)$.

Однако если подставить в \eqref{12_2} значение $\phi = 1$, то получится процесс \textbf{случайного блуждания}, не являющийся стационарным, так как $\var y_t = \sigma^2 t$; тем более не являются стационарными процессами процессы с $|\phi| > 1$.
В общем случае аналогичная проблема возникает, если многочлен $A(L)$ из \eqref{12_1} имеет единичный корень.


\begin{definition}[интегрируемый ряд]
    Рассмотрим нестационарный ряд $x_t$.
    Назовем ряд $\Delta x_t = x_t - x_{t-1}$ рядом из разностей $x_t$ первого порядка.
    Разностью $k+1$ порядка называется ряд из разностей ряда разностей $k$-го порядка.
    Исходный ряд $x_t$ называется \textbf{интегрируемым порядка $k$, $I(k)$}, если он сам и его разности до $k-1$ порядка нестационарны, а разности $k$-го порядка стационарны.
    Стационарный ряд также считается интегрируемым рядом порядка $0$.
\end{definition}

\begin{definition}[Коинтеграция]
    Пусть два ряда $x_t, y_t$ таковы, что некоторая их линейная комбинация $y_t - \beta x_t$ стационарна.
    Тогда эти ряды называются \textbf{коинтегрированными}.
\end{definition}

В таком случае можно получить состоятельную оценку для $\beta$, применив МНК к уравнению
\begin{equation*}
    y_t = \alpha + \beta x_t + \eps_t.
\end{equation*}

Однако в отличие от обычной оценки распределение $\sqrt{n} \left( \hat\beta - \beta \right)$ не является нормальным.


\begin{definition}[Автокорреляционная функция]
    Автокорреляционной функцией (ACF) стационарного ряда $y_t$ называется коэффициент корреляции между $y_t$ и $y_{t-k}$ в зависимости от $k$:
    \begin{equation*}
        \rho_k = \frac{\cov\left( y_t, y_{t-k} \right)}{\var y_t}.
    \end{equation*}
\end{definition}

\begin{definition}[Частичная автокорреляционная функция]
    Частичной автокорреляционной функцией (PACF) стационарного ряда $y_t$ называется коэффициент корреляции между $y_t$ и $y_{t-k}$ в зависимости от $k$ при исключении влияния промежуточных значений $y_{t-1}, \dots y_{t-k+1}$. Более формально, значение $\mathrm{PACF}(k)$ вычисляется как коэффициент $\beta_k$ в МНК-решении следующего регрессионного уравнения:
    \begin{equation*}
        y_t = \beta_0 + \beta_1 y_{t-1} + \beta_2 y_{t-2} + \dots + \beta_k y_{t-k} + \eps_t
    \end{equation*}
\end{definition}





















