% Предсказательная сложность. Обучаемость и предсказуемость. Обучение в случае распределения, допускающего параметризацию.

Существует несколько подходов к формальному определению понятия сложности системы.
В контексте временных рядов рассматриваются следующие подходы:
\begin{enumerate}
\item
    Колмогоровская сложность -- длина наиболее короткого описания ряда. Под описанием ряда здесь понимается алгоритм, генерирующий данный ряд;
\item
    Предсказательная сложность -- некая мера, показывающая, насколько сложно прогнозировать данный временной ряд.
\end{enumerate}

Сконцентрируемся далее на предсказательной сложности.
Рассмотрим временной ряд $x(t)$.
Будем считать, что нам известны значения ряда $x_p$ на промежутке $t \in \left( -T, 0 \right)$ и мы пытаемся предсказать значения $x_f$ на промежутке $t \in \left( 0, T' \right)$.
Для краткости обозначим эти два промежутка как <<прошлое>> и <<будущее>>.

Какова бы ни была система, генерирующая ряд $x(t)$, существуют распределения $P(x_p)$, $P(x_f)$, $P(x_f | x_p)$.
Определим \textbf{предсказательную информацию} следующим образом:
\begin{gather*}
    \mathcal{I}_{\text{pred}}\left( T, T' \right) =
    \left\langle \log_2 \left( \frac{P(x_f | x_p)}{P(x_f)} \right) \right\rangle =
    \left\langle \log_2 P(x_f, x_p) \right\rangle - \left\langle \log_2 P(x_f) \right\rangle - \left\langle \log_2 P(x_p) \right\rangle,
\end{gather*}
где под $\left\langle\tau\right\rangle$ понимается усреднение величины $\tau$ по совместному распределению $P(x_p, x_f)$.
Очевидно, что если будущие значения не зависят от прошлых, то предсказательная информация равна $0$, а если $x_f$, наоборот, однозначно определяется значениями $x_p$, то $\mathcal{I}_{\text{pred}}$ стремится к бесконечности.
\footnote{Авторы данного документа, рассмотрев тривиальный случай, получили в результате $\log_2 \delta(0)$. Съезд постановил, что это значение вполне корректно считать бесконечностью.}

Если распределения ряда не зависят от времени, по крайней мере, до некоторого горизонта стационарности, то каждое слагаемое в последнем уравнении представляет собой энтропию распределения значений ряда на интервале фиксированной длины:
\begin{equation}
\label{10_1}
    \mathcal{I}_{\text{pred}}\left( T, T' \right) =
    \dots =
    S(T) + S(T') - S(T + T').
\end{equation}


По аналогии с физическими процессами, % TODO: так в оригинале!
энтропия $S(T)$ асимптотически линейна по времени, то есть:
\begin{equation}
\label{10_2}
    S(T) = S_0 \cdot T + S_1(T),
\end{equation}
где $S_0 = \const$, $\frac{S_1(T)}{T} \to 0$, $S_1(T) \ge 0$.
Слагаемые в \eqref{10_2} называются \textbf{экстенсивной} и \textbf{субэкстенсивной} составляющими энтропии соответственно.

Подставляя \eqref{10_2} в \eqref{10_1}, получаем асимптотику предсказательной информации при прогнозировании на бесконечно долгий период:
\begin{equation*}
    I_{\text{pred}}(T) =
    \lim_{T' \to\infty} \mathcal{I}_{\text{pred}}\left( T, T' \right) =
    \lim_{T' \to\infty} \left( S_1(T) + S_1(T') - S_1(T+T') \right) =
    S_1(T).
\end{equation*}
Полученная величина называется \textbf{предсказательной сложностью}.

Следует отметить, что возможны только три случая асимптотического поведения $I_{\text{pred}}(T)$:
\begin{enumerate}
\item
    $\lim_{T \to \infty} I_{\text{pred}}(T) = \const$, то есть наблюдение за системой в течение сколь угодно долгого времени позволяет извлечь лишь конечное количество информации о будущих значениях.
    Такое поведение встречается в регулярных системах, поведение которых можно точно предсказать на сколь угодно долгий срок вперед и в системах, где отсутствует зависимость от прошлого, за исключением последнего наблюденного значения (например, Марковские процессы).
\item
    $I_{\text{pred}}(T) \sim \log T$.
\item
    $I_{\text{pred}}(T) \sim T^{\mu}$, где $0 < \mu < 1$.
\end{enumerate}


