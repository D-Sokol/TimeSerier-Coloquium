% Энтропия Колмогорова-Синая.

\begin{definition}[Энтропия Колмогорова-Синая]
    Рассмотрим динамическую систему с дискретным временем $x_{n+1} = f(x_n)$ или с дискретизованным непрерывным временем $x(t+\tau) = \phi^\tau(x(t))$.
    Разобьем фазовое пространство на непересекающиеся множества $A_i$, такие, что $\diam A_i < \eps$ по любой метрике, например, Евклидовой.
    
    Тогда введем следующую последовательность разбиений:
    \begin{equation*}
        A_{i_1 i_2 \dots i_k} = \bigcap_{j=1}^{k} f^{1-j}\left( A_{i_j} \right),
    \end{equation*}
    то есть отнесем точку $x$ к множеству $A_{i_1 i_2 \dots i_k}$, если изначально она находится в множестве $A_{i_1}$, после одного временного шага в множестве $A_{i_2}$ и так далее до $A_{i_k}$.
    Заметим, что некоторые из построенных множеств (или даже подавляющее большинство) могут быть пустыми.
    
    Для каждого разбиения глубины $k$ подсчитаем энтропию Шеннона, соответствующую инвариантной мере системы $\mu$:
    \begin{equation*}
        H\left( k \right) = - \sum_{i \in \{1,\dots,N\}^k} \mu\left( A_{*i} \right) \log \mu\left( A_{*i} \right)
    \end{equation*}
    
    Тогда \textbf{метрической энтропией} или \textbf{энтропией Колмогорова-Синая} называется предельное приращение $H(k)$ при росте $k$:
    \begin{equation*}
        K =
        \lim_{\eps \to 0} \lim_{k \to \infty} \left( H(k+1) - H(k) \right) =
        \lim_{\eps \to 0} \lim_{k \to \infty} \frac{H(k)}{k}
    \end{equation*}
\end{definition}

Для хаотических систем $K > 0$, что означает, что любое конечное количество информации о системе в начальный момент времени постепенно перестает быть хоть сколько-нибудь полезным в силу нарастания неопределенности. О таких системах говорят, что они производят информацию. Для регулярных динамических систем $K = 0$.

